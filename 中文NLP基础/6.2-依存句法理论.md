6.2 依存句法理论

依存句法是由法国语言学家泰斯尼耶尔（Lucien Tesnière）最早提出的。同时，他也是配价理论的奠基人。这两个概念都出现在他的鸿篇巨著——《结构句法基础》之中。因此，由于两者一脉相承的关系，我们将配价语法与依存句法放在同一章节（6.2节）来介绍。

依存句法代表了句法分析的另一个语法体系。与转换生成语法不同，依存语法和配价理论虽然诞生在法国，但发展壮大却是在德国。由于乔姆斯基的短语结构语法在解析德语时，精度明显低于英语，只能达到70%左右。这是由于德语中词序更为自由而导致的。为此迫使人们选择另一种语法体系，才开始注意到了依存句法理论。

一开始，人们对依存句法普遍有一种误解，认为它是短语结构文法的一种补充，但随着理论研究的深入，人们发现，依存句法不仅具有形式简洁、易于标注、便于应用等优点，更因为它与转换生成语法截然不同，完全是另一种句法体系。

Percival（1990）将依存关系分为两种：一种是句法依存，是指如果有两类元素，其中有一类元素只是在另一类出现时才会出现，那么就说前一类的元素在句法上依存于后一类元素；另一种是语义依存，是指某些词的出现只是为了限定其他词的意义。

这与单纯从语法角度来分析句子的转换生成语法有了很大的不同。依存句法的依存关系中可以同时容纳句子的语法结构和语义结构的两种关系。近些年，认知科学的累累硕果使人们逐渐将目光从语法转向语义层面，希望两种标注并存的句法新理论对提高句子的识别精度会带来质的飞跃。

### 6.2.1 配价理论

配价理论源于一种形象的类比。泰斯尼耶尔把句子比喻成化学元素中的分子，分子是由原子按照一定的价结合到一起的。动词是句子的“中心”，所有的成分都是围绕着句子的中心动词展开的。那么，“中心”动词的价就决定了句子的成分结构。他称那些被中心动词直接支配的成分为“行动元”，那些起到辅助作用的成分为“状态元”。一个动词能够带的行动元个数就是它的价。为此他说：

“可以把动词比作一个带钩的原子，动词用这些钩子来吸引与其数量相同的行动元作为自己的从属成分。一个动词所具有的钩子的数量，即动词所能支配的行动元的数目，就构成了我们所说的动词的配价。”

“应该指出的是，不必总是要求动词依照其配价带全所有的行动元，或者说让动词达到饱和状态。有些价可以不用或空缺。”

为此，他还作了形象的类比：动词代表一整出小戏剧，其中必然包括情节过程，大多数也包括人物和环境。如果将戏剧语言移用到配价理论中来，那么情节过程、人物和环境就分别成为动词、行动元和状态元。其中，动词表示情节过程。例如，句子“张三 在街上 碰见 李四”中，情节过程通过动词“碰见”表示出来；行动元指参与情节的人和事物，它通常由名词性词语充当，如上例中的“张三”、“李四”；状态元表示情节过程发生的时间、地点、方式等的环境，它由副词性词语充当；如上例中的“在街上”。动词是全句的支配成分，行动元则是动词的直接支配成分，而状态元是动词的辅助成分。

泰斯尼耶尔的“小戏”的说法很生动，它成为动词中心说和配价理论的经典比喻。动词的配价是配价语法的主体内容。早期的配价语法只包括动词的配价，现在，在计算语言学领域所指的配价也仍然以动词的配价为主。后来，泰斯尼耶尔在动词配价理论基础之上做了进一步发展，将配价理论发展到了其他类型的实词。更重要的是，在考察各种实词之间的支配关系时，泰斯尼耶尔逐渐形成了依存句法的思想。

确定一个动词的配价要求确定动词的价数、价质和价形。所谓价数就是指动词能够支配的配价成分的数量。根据动词的价数，将动词分为零价、一价、二价、三价等类型。所谓价质（价义）就是指动词的配价成分的语义性质（语义角色），如施事、受事、与事等。所谓价形就是指动词的各种配价成分能够出现的句法位置，如主语、宾语、状语、补语等位置。也就是动词与配价成分能够构成什么样的句式。

配价语法的概念并不复杂，它揭开了通向认知语义的大门。人们后来发现，认知语言学中的主体——背景理论，以及由此发展而来的意象图式理论与其有天然的联系。随着对配价理论的深入研究，人们提出了谓词论元的理论，把动词直接支配的行动元定义为核心论元，把动词间接支配的状态元定义为辅助论元。谓语动词及其核心论元和辅助论元最后都称为句子的语义角色，这区别于句子的语法成分，成为识别句义的一种新的标注系统。在本书的后面章节还会详细介绍。

需要特别说明的是，价数、价质和价形这种三位一体的识别模式，最近又引起了学界的重视，并以此为基本方法论，重新设计专门的算法来解决多年以来都难于处理的句子句法和语义识别的精度问题。

在中国，语言学界引入配价语法理论的时间始于1978年。30多年来，汉语的语言学和计算语言学的研究者对其进行了充分的研究，除发表了数百篇论文之外，还建立了较大规模的配价词典库。配价语法作为依存句法的理论基础早已成为汉语计算语言学的基础理论之一。

### 6.2.2 配价词典

配价理论一经产生之后，就面临着依据什么标准来确定动词价数这个问题。不同的学者提出了不同的标准。有的认为根据动词的意义来确定动词的配价，如动词“买”在语义上涉及4种必要成分：买者、卖者、买卖的物品和价格，那么“买”就是四价动词；有的认为根据成分的句法位置区分配价成分（必有论元）和非配价成分（可有论元）。早期的学者只将动词的主语和宾语看作配价成分，不能充当主语或宾语的成分不算配价成分。还有的根据成分的语义角色区分配价成分（必有论元）和非配价成分（可有论元）。早期的学者只承认施事（主体）、受事（客体）和与事三种语义成分为配价成分，其他语义成分都不算配价成分，等等，不一而足。这种矛盾来源于价数、价质和价形这三种指标的定义各不相同。

为了统一认识，人们开始从实际语料中寻求答案，这就导致了配价词典的产生。世界上第一部配价词典的作者是德国的语言学家Helbig，他总结了构造配价词典条目的如下6个步骤：

（1）分析动词对应的谓词的逻辑语义结构，找出形成完整谓词结构的可词汇化论元的数量。

（2）标出动词具有的语义特征。

（3）为动词标示语义格，也就是为第一步得到的那些论元赋予明确的语义角色，如施事、受事、地点、工具等。

（4）对可词汇化的论元进行语义指称分析，并进行诸如[±Anim]、[±Hum]、[±Abstr]之类的语义特征标识。

（5）处理从语义层到句法层的映射问题，要考虑如下两种情况。

一是按照句子的功能成分，如主语、宾语等，二是按照句子成分的形态表示，如名词是什么格，介词短语的类型等，这是对行动元（补足语）的定性描述。

（6）给定词项行动元（补足语）的定量描述，也就是给出动词项的价数，应区分必有和可有补足语。

Helbig提出的确定配价的六原则模型要求在构造某种语言的配价词典（表）之前，要对动词进行细致的分类，要有一个语义格关系表，要有区别名词性成分的一套语义标记。此外，还要有一套适合该话言的句法关系集。

由此可见，按照Helbig的方法构建的语言词典是烦琐的，后人在此基础上进行了简化。就汉语而言，北大的配价词典最为著名。以北大的配价词典为例，看看汉语的配价词典的一些实例。

例：动词“吃”（见表6.3）。

表6.3 配价词典案例

| Lexicon（词汇）         | 吃                                                           | Lexicon（词汇）         | 吃                             |
| ----------------------- | ------------------------------------------------------------ | ----------------------- | ------------------------------ |
| pin_yin（拼音）         | chi1                                                         | pin_yin（拼音）         | chi1                           |
| sem_indx（义项序列）    | 1                                                            | sem_indx（义项序列）    | 2                              |
| semantics（语义）       | —                                                            | semantics（语义）       | 受、挨                         |
| sem_taxonomy（语义类）  | 身体活动                                                     | sem_taxonomy（语义类）  | 其他行为                       |
| coord_valence（配价数） | 2                                                            | coord_valence（配价数） | 2                              |
| Subject（主语）         | 人                                                           | Subject（主语）         | 人                             |
| Object（宾语）          | 食物\|药物                                                   | Object（宾语）          | 抽象事物                       |
| dative_role（格角色）   | —                                                            | dative_role（格角色）   | —                              |
| Example（例句）         | 吃食堂／吃药／吃靠山／吃力／吃在胃里／正吃着呢！／吃坏了胃／这种菜吃了吃觉得很不错／野菜很吃油／吃软不吃硬 | Example（例句）         | 吃亏／吃苦／吃惊／你先吃上一拳 |

注：访问网址：http://ccl.pku.edu.cn/ccl_sem_dict/。本例的词条来源于最初的版本，由于最新版的语义词典做了更新，可能词项有所变化。

北大语义配价词典的基本信息如下。

❑ Lexicon（词汇）和pin_yin（拼音）。词汇的基本信息：名称、汉语拼音。

❑ sem_indx（义项序列）和semantics（语义）。同一词汇有不同的义项，词汇的配价也要根据义项的不同分别定义。

❑ sem_taxonomy（语义类）。指定词汇所属的语义类。

❑ coord_valence（配价数）和Subject（主语）、Object（宾语）。使词汇的配价数与句法成分建立关联。

❑ dative_role（格角色）：定义词汇的语义格。

❑ Example（例句）：给出词汇在语料中的实例。

### 6.2.3 依存理论概述

所谓依存句法，需要理解的关键概念在于依存。泰斯尼耶尔认为句子中各个成分之间都存在着支配与从属的关系。处于支配地位的词称为支配词（Head），也称为核心词；处于被支配地位的词称为从属词（Dependency），也称为修饰词。他认为，句子的结构表现为各个构成成分之间的层层递进的从属关系，它的顶端就成为一个支配所有成分的“中心结”（根节点）。“中心结”在绝大多数的情况下是动词，也就是说，动词是句子的中心。这种思想显然来自配价理论。

而句子各个成分之间的支配关系与被支配关系是单向的。因此，就很自然地构成了一棵以动词为中心的句法树。与前面的章节相同，类似的实例（实例中的词性标签，使用Ltp的标注规则）如下。

张三/nh参加/v了/u这次/r会议/n

上述句子是分词、词性标注之后得到的结果，把它写成列表的形式，如表6.4所示。

表6.4 结果的列表形式

| 0    | 张三 | nh   |
| ---- | ---- | ---- |
| 1    | 参加 | v    |
| 2    | 了   | u    |
| 3    | 这次 | r    |
| 4    | 会议 | n    |

第一列为词索引，第二列为词汇，第三列为词性标注。

按照依存句法的要求，定义动词为根节点，在新加入的依存关系列中，给出根节点的序号为0，如表6.5所示。

表6.5 给出根节点的序号为0

| 0    | 张三 | nh   |      |
| ---- | ---- | ---- | ---- |
| 1    | 参加 | v    | 0    |
| 2    | 了   | u    |      |
| 3    | 这次 | r    |      |
| 4    | 会议 | n    |      |

按照词汇的依存关系，再依次将剩下节点的依存关系补全，如表6.6所示。

表6.6 依次将剩下节点的依存关系补全

| 0    | 张三 | nh   | 1    |
| ---- | ---- | ---- | ---- |
| 1    | 参加 | v    | 0    |
| 2    | 了   | u    | 1    |
| 3    | 这次 | r    | 4    |
| 4    | 会议 | n    | 1    |

除“这次”这个词依赖于会议之外，其他词都依赖于根节点。

最后，标识出每个依存弧的名称。注意，这里使用的Ltp 3.3的依存关系集（详见下文）。这样就完成了一棵句法依存树的绘制。依存句法的生成如表6.7所示。

表6.7 依存句法的生成

![img](https://cdn.nlark.com/yuque/0/2021/jpeg/21473765/1631784694667-4156b412-2e8c-4268-8e9b-b3ca38b97d18.jpeg)

最后，同时使用NLTK库和LTP-cloud的可视化模块来显示这棵句法树的树状图，如图6.18所示。

![img](https://cdn.nlark.com/yuque/0/2021/jpeg/21473765/1631784695084-fb7d8183-5566-4c3d-b91f-f9c4b143e99a.jpeg)

图6.18 NLTK和Ltp的依存句法树

图6.18中的两幅图中，NLTK无法显示依存弧的方向和关系名称。而LTP的图形化显示不仅能够给出树状图，还给出了依存关系。这种句法树称为“依存树”（Dependency Tree）。

直观上，从上述流程中我们可以观察到依存语法与短语结构语法的相似之处，它们都将句子表示为一个树状的结构。所不同的是，依存树上连接词汇的每条弧代表了词汇之间的支配与从属的关系。“参加”这个根节点直接支配句子中除“这次”之外的其他词汇。“这次”修饰了核心词“会议”，因此被“会议”支配。整个句子形成了一个三层的树状结构。

这是因为，依存关系是一种非对称的关系，这构成了层级的基础。因为一个元素可以支配和被支配，也因为每一个句子都是一个整体，所以句子可以被表示成这种树形结构。句子的中心称为根节点，句中所有其他元素都直接或间接地受根节点的支配。

同时还揭示出，句子是一个有组织的单位，其基本组成元素是词。联系产生了句子元素间的依存关系，所有这些联系就形成了句子的框架。因此，联系是概念联结的一种句法实现。同时，这种联系是说话人有意为之的（遣词造句）。也就是说，元素间的联系不仅要符合一定的规则，还要具有一定的语义。整个句子的意义不仅由句子的元素——词汇所确定，也要由各元素之间的联系所确定。联系使得用一个句子来表达一种完整的思想成为可能。

进一步来看，一个句子同时具有句法和语义结构。理解一个句子意味着掌握组成句子结构的所有联系。因为句法结构必须反映语义结构，所以句法结构和语义结构是平行的。而且，如同句法结构一样，语义结构也是二维的。

中国著名的计算语言学家冯志伟提出依存树应该满足如下5个条件。

❑ 单纯节点条件：在泰斯尼耶尔的“依存树”中，只有终极节点，没有非终极节点。也就是说，依存树中的所有节点所代表的都是句子中实际出现的具体的单词。当然，根据多标记的原理，依存树中的单词也可以是多标记的，再标以“词类”“静态语义特征”等信息。

❑ 单一父节点条件：在依存树中，除根节点没有父节点之外，所有的节点都只有一个父节点。父节点的方向指向子女节点，而不是相反。在数学上，这是一种非对称的、可传递的关系。

❑ 独根节点条件：一个依存树只能有一个根节点。这个根节点，也就是依存树中唯一没有父节点的节点，这个根节点支配着其他的所有的节点。

❑ 非交条件：依存树中的树枝不能彼此相交。

❑ 互斥条件：依存树中的节点之间，从上到下的支配关系和从左到右的前于关系是互相排斥的。也就是说，如果两个节点之间存在着支配关系，那么，它们之间就不能存在前于关系。

冯志伟提出的依存树这5个条件，更加形象地描述了依存树中各个节点之间的联系，显然更加直观、更加便于使用。

### 6.2.4 Ltp依存分析介绍

CoNLL是由SIGNLL组织的年度会议，有关会议的网址参见：http://www.conll.org/。该会议从1997年的第一届开始，到现在（2016年）已经举办了20届，是NLP学界中最权威、最著名的研究会议。会议每年都发布一些最新的NLP研究成果，所有的论文都发布在ACL Anthology（http://www.aclweb.org/anthology/）上，可以自由下载。

与短语结构树一样，依存树也包含数据表示和图形表示两种结构。各种机构曾经都提供了依存句法树的数据表示，自然语言研究会（Conference on Natural Language Learning, CoNLL）也提供了自己的标注规范，CoNLL会定期发布一些NLP的共享任务（Share Task），影响力比较大。CoNLL规范已经成为一种表示语言分析结果的通用格式。

最初CoNLL标注格式一共包含10列，但实际使用的一般为8列，如表6.8所示。

表6.8 CoNLL标签说明

| 1    | ID      | 当前词在句子中的序号，从1开始                            |
| ---- | ------- | -------------------------------------------------------- |
| 2    | FORM    | 当前词语或标点                                           |
| 3    | LEMMA   | 当前词语（或标点）的原型或词干，在中文中，此列与FORM相同 |
| 4    | CPOSTAG | 当前词语的词性（粗粒度）                                 |
| 5    | POSTAG  | 当前词语的词性（细粒度）                                 |
| 6    | FEATS   | 句法特征，此列未被使用，全部以下画线代替                 |
| 7    | HEAD    | 当前词语的中心词                                         |
| 8    | DEPREL  | 当前词语与中心词的依存关系                               |

各家研究机构根据自己的需求都做了一些调整，以Ltp-Cloud（Ltp语言云）上提供的依存句法系统为例，其数据标注规范如表6.9所示。

表6.9 数据标注规范

| 列号 | 含义                                                   |
| ---- | ------------------------------------------------------ |
| 1    | 单词在句子中的标号，从0开始                            |
| 2    | 单词本身                                               |
| 3    | 空                                                     |
| 4    | 空                                                     |
| 5    | 单词词性标注信息                                       |
| 6    | 未登录词信息                                           |
| 7    | 依存句法关系中的父节点标号                             |
| 8    | 依存句法关系类型                                       |
| 9    | 空                                                     |
| 10   | 空                                                     |
| 11   | 如果单词是语义角色标注中的谓词，则为单词本身，否则为空 |
| 12   | 每个谓词占一列，每一列为该谓词的语义角色标注信息       |

如表6.9所示，在Ltp语言云的CoNLL格式中，分析结果的每一行代表句子中每个词的信息，词标号从0开始。分析结果的基础列有10列，之后的每一列代表文本中的语义信息，每列之间用Tab分割。此列值为空用"_"占位。下面给出Ltp-Cloud的CoNLL语言云的一个实例。

使用的例句与上例相同：张三参加了这次会议。

在浏览器地址栏输入：

http://api.ltp-cloud.com/analysis/? api_key=YourApiKey&text=张三参加了这次会议。&pattern=all&format=conll

上述链接中的YourApiKey是用户注册http://www.ltp-cloud.com/网站后，系统生成的一个api_key，每个用户的api_key都不相同。输入你自己的YourApi_Key之后，链接地址返回对例句的全部解析结果如图6.19所示。

![img](https://cdn.nlark.com/yuque/0/2021/jpeg/21473765/1631784695610-7d866696-5892-46d1-85d9-31fd7f054361.jpeg)

图6.19 LTP的CoNLL依存解析结果

最后，给出返回的CoNLL的数据在pyltp中的显示代码，输出结果中略去了空列、未登录词列和语义角色标注列，内容如下。

​        \# -＊- coding: utf-8 -＊-

​        import sys, os

​        from pyltp import ＊

​        reload(sys)

​        sys.setdefaultencoding('utf-8')

​        words = "张三 参加 了 这次 会议 。".split(" ")

​        postagger = Postagger()

​        postagger.load("X:\\nltk_data\\ltp3.3\\pos.model")

​        postags = postagger.postag(words)

​        parser = Parser()

​        parser.load("X:\\nltk_data\\ltp3.3\\parser.model")

​        arcs = parser.parse(words, postags)

​        arclen = len(arcs)

​        conll = ""

​        for i in xrange(arclen):

​            if arcs[i].head ==0:

​                arcs[i].relation = "ROOT"

​            conll += str(i)+"\t"+words[i]+"\t"+postags[i]+"\t"+str(arcs[i].head-1)+"\

​    t"+arcs[i].relation+"\n"

​        print conll

输出结果如下。

​        0   张三 nh   1    SBV

​        1   参加 v    -1   ROOT

​        2   了   u    1    RAD

​        3   这次 r    4    ATT

​        4   会议 n    1    VOB

​        5   。   wp   1    WP

LTP的依存关系标签比较直观，主要识别句子中的“主、谓、宾、定、状、补”这些语法成分，并分析语言单位内成分之间的依存关系揭示其句法结构。LTP的依存句法解析标签如表6.10所示。

表6.10 LTP的依存句法解析标签

| 关系类型   | Tag  | Description               | Example                   |
| ---------- | ---- | ------------------------- | ------------------------- |
| 主谓关系   | SBV  | subject-verb              | 我送她一束花（我<--送）   |
| 动宾关系   | VOB  | 直接宾语，verb-object     | 我送她一束花（送-->花）   |
| 间宾关系   | IOB  | 间接宾语，indirect-object | 我送她一束花（送-->她）   |
| 前置宾语   | FOB  | 前置宾语，fronting-object | 他什么书都读（书<--读）   |
| 兼语       | DBL  | double                    | 他请我吃饭（请-->我）     |
| 定中关系   | ATT  | attribute                 | 红苹果（红<--苹果）       |
| 状中结构   | ADV  | adverbial                 | 非常美丽（非常<--美丽）   |
| 动补结构   | CMP  | complement                | 做完了作业（做-->完）     |
| 并列关系   | COO  | Coordinate                | 大山和大海（大山-->大海） |
| 介宾关系   | POB  | preposition-object        | 在贸易区内（在-->内）     |
| 左附加关系 | LAD  | left adjunct              | 大山和大海（和<--大海）   |
| 右附加关系 | RAD  | right adjunct             | 孩子们（孩子-->们）       |
| 独立结构   | IS   | independent structure     | 两个单句在结构上彼此独立  |
| 核心关系   | HED  | head                      | 指整个句子的核心          |

### 6.2.5 Stanford依存转换、解析

Stanford Parser系统是一个可进行短语结构和依存结构分析的解析器，并提供了多种句法树解析算法，相比于LTP Parser对依存树的处理要复杂得多。Stanford处理依存句法树的内容如下。

（1）支持短语结构树转换为依存句法树。

​                      package edu.stanford.nlp.ademo;

​                      import java.util.Collection;

​                      import edu.stanford.nlp.parser.lexparser.LexicalizedParser;

​                      import edu.stanford.nlp.trees.GrammaticalStructure;

​                      import edu.stanford.nlp.trees.GrammaticalStructureFactory;

​                      import edu.stanford.nlp.trees.Tree;

​                      import edu.stanford.nlp.trees.TreebankLanguagePack;

​                      import edu.stanford.nlp.trees.TypedDependency;

​                      public class PCFGDEPDemo {

​                          public static void main(String[] args) {

​                               LexicalizedParser lp = LexicalizedParser.loadModel("models/lexparser/

​                  chinesePCFG.ser.gz"); //加载模型

​                               Tree parse = Tree.valueOf("(ROOT  (IP (NP (NR 张三)) (VP (VV 参加) (AS 了)

​                  (NP (DT 这次) (NN 会议)))))"); //字符串形式的短语结构树

​                               TreebankLanguagePack tlp = lp.getOp().langpack();

​                               GrammaticalStructureFactory gsf = tlp.grammaticalStructureFactory();

​                               GrammaticalStructure gs = gsf.newGrammaticalStructure(parse);

​                               // 依存关系，以CoNLL的形式显示

​                               System.out.println(GrammaticalStructure.dependenciesToString(gs,

​                                        gs.typedDependencies(), parse, true, false));

​                               // 依存关系，以stanford 常规的形式显示

​                               Collection<TypedDependency> tdl = gs.allTypedDependencies();

​                               System.out.println(tdl);

​                               System.out.println();

​                          }

​                      }

输出结果如下。

​                      1   张三 _    NR  NR  _    2    nsubj    _    _

​                      2   参加 _    VV  VV  _    0    root_    _

​                      3   了   _    AS  AS  _    2    asp _    _

​                      4   这次 _    DT  DT  _    5    dep _    _

​                      5   会议 _    NN  NN  _    2    dobj_    _

​                      [nsubj(参加-2, 张三-1), root(ROOT-0, 参加-2), asp(参加-2, 了-3), dep(会议-5, 这次-4),

​                  dobj(参加-2, 会议-5)]

注意，根节点序号从0开始，而不是LTP的-1。

（2）可以使用多种算法得到依存句法树，这里提供基于LSTM神经网络依存解析器的测试代码。

​        package edu.stanford.nlp.ademo;

​        import java.io.StringReader;

​        import java.util.Collection;

​        import java.util.List;

​        import edu.stanford.nlp.ling.HasWord;

​        import edu.stanford.nlp.ling.TaggedWord;

​        import edu.stanford.nlp.parser.nndep.DependencyParser;

​        import edu.stanford.nlp.process.DocumentPreprocessor;

​        import edu.stanford.nlp.tagger.maxent.MaxentTagger;

​        import edu.stanford.nlp.trees.GrammaticalStructure;

​        import edu.stanford.nlp.trees.TypedDependency;

​        public class NNDepDemo {

​            public static void main(String[] args) {

​                String modelPath = "models/parser/nndep/CTB_CoNLL_params.txt.gz";

​                String taggerPath = "models/pos-tagger/chinese-distsim/chinese-distsim.

​    tagger";

​                String text = "张三 参加 了 这次 会议";

​                MaxentTagger tagger = new MaxentTagger(taggerPath);

​                DependencyParser parser = DependencyParser.loadFromModelFile(modelPath);

​                DocumentPreprocessor tokenizer = new DocumentPreprocessor(new StringReader

​    (text));

​                for (List<HasWord> sentence : tokenizer) {

​                  List<TaggedWord> tagged = tagger.tagSentence(sentence);

​                  GrammaticalStructure gs = parser.predict(tagged);

​                  Collection<TypedDependency> tdl = gs.allTypedDependencies();

​                  System.out.println(tdl);

​                }

​            }

​        }

输出结果如下。

​        [VMOD(参加-2, 张三-1), root(ROOT-0, 参加-2), VMOD(参加-2, 了-3), NMOD(会议-5, 这次

​    -4), OBJ(参加-2, 会议-5)]

（3）给出复杂的Stanford依存句法标注体系。

该标注体系的完整内容列于http://universaldependencies.org/docs/u/dep/index.html中。用户可以参照网页具体的内容来了解每种标签的意义。一些常用的依存标签的中文说明如下。括号内为例子词汇。

中心语为谓词。

Subj——主语。

nsubj——名词性主语（nominal subject）（同步，建设）。

top——主题（topic）（是，建筑）。

npsubj——被动型主语（nominal passive subject），专指由“被”引导的被动句中的主语，一般是谓词语义上的受事（称作，镍）。

csubj——从句主语（clausal subject），中文不存在。

xsubj——x主语，一般一个主语下面含多个从句（完善，有些）。

中心语为谓词或介词。

obj——宾语。

dobj——直接宾语（颁布，文件）。

iobj——间接宾语（indirect object），基本不存在。

range——间接宾语为数量词，又称为与格（成交，元）。

pobj——介词宾语（根据，要求）。

lobj——时间介词（来，近年）。

中心语为谓词。

comp——补语。

ccomp——从句补语，一般由两个动词构成，中心语引导后一个动词所在的从句（IP） （出现，纳入）。

xcomp——x从句补语（xclausal complement），不存在。

acomp——形容词补语（adjectival complement）。

tcomp——时间补语（temporal complement）（遇到，以前）。

lccomp——位置补语（localizer complement）（占，以上）。

rscomp——结果补语（resultative complement）。

中心语为名词。

mod——修饰语（modifier）。

pass——被动修饰（passive）。

tmod——时间修饰（temporal modifier）。

rcmod——关系从句修饰（relative clause modifier）（问题，遇到）。

numod——数量修饰（numeric modifier）（规定，若干）。

ornmod——序数修饰（numeric modifier）。

clf——类别修饰（classifier modifier）（文件，件）。

nmod——复合名词修饰（noun compound modifier）（浦东，上海）。

amod——形容词修饰（adjetive modifier）（情况，新）。

advmod——副词修饰（adverbial modifier）（做到，基本）。

vmod——动词修饰（verb modifier, participle modifier）。

prnmod——插入词修饰（parenthetical modifier）。

neg——不定修饰（negative modifier）（遇到，不）。

det——限定词修饰（determiner modifier）（活动，这些）。

possm——所属标记（possessive marker）, NP。

poss——所属修饰（possessive modifier）, NP。

dvpm——DVP标记（dvp marker）, DVP（简单，的）。

dvpmod——DVP修饰（dvp modifier）, DVP（采取，简单）。

assm——关联标记（associative marker）, DNP（开发，的）。

assmod——关联修饰（associative modifier）, NP|QP（教训，特区）。

prep——介词修饰（prepositional modifier）NP|VP|IP（采取，对）。

clmod——从句修饰（clause modifier）（因为，开始）。

plmod——介词性地点修饰（prepositional localizer modifier）（在，上）。

asp——时态标词（aspect marker）（做到，了）。

partmod——分词修饰（participial modifier）不存在。

etc——等关系（etc）（办法，等）。

中心语为实词。

conj——联合（conjunct）。

cop——系动（copula）双指助动词。

cc——连接（coordination），指中心词与连词（开发，与）。

其他。

attr——属性关系（是，工程）。

cordmod——并列联合动词（coordinated verb compound）（颁布，实行）。

mmod——情态动词（modal verb）（得到，能）。

ba——“把”字关系。

tclaus——时间从句（以后，积累）。

cpm——补语化成分（complementizer），一般指“的”引导的CP（振兴，的）。
