5.1 汉语词性标注

第1章和第3章都介绍过汉语分词模块。第3章还通过《北大规范》词性表引入了词性的一些基本标签。从本节开始对汉语词性标注进行详细介绍。

### 5.1.1 汉语的词性

什么是词性（Part-of-Speech, POS）呢？词性，也称为词类，是词汇的语法属性，是连接词汇到句法的桥梁。由于汉语缺乏形态变化，一个词的词性与它在句子中的成分密切相关。

游泳是一种很好的健身运动（名词，表示这一运动）。

下午，我去体育馆游泳（动词，表示这一动作）。

同一个词，因为在句子中扮演的角色不同，其词性也不相同。我们都知道，在传统的语法学中，汉语句子分为主语、谓语、宾语、定语、状语、补语6个成分。单从词性的角度来看，主语和宾语都是名词性结构，多是名词、代词；谓语则多是动词、形容词；定语修饰、限制名词性结构，多是名词、代词、数量词、形容词；状语修饰、限制动词或形容词，多是形容词、副词、数量词；补语是动词或形容词后面的连带成分，也多是形容词、副词、数量词。因此，从句法的角度来看，一个词的词性是由它在句子中的成分所决定的。这才是划分词类的依据。

一个词的词类（词性）是指，在一个语言中，众多具有相同句法功能、能在同样的组合位置中出现的词，聚合在一起形成的范畴。词类是最普遍的语法的聚合。汉语中的词类划分具有层次性。大的分类可以分成实词和虚词，实词又包括体词、谓词等，体词中又可以分出名词和代词等。现代汉语的词可以分为两类12种词性（一说是14种）。一类是实词：名词、动词、形容词、数词、量词和代词。另一类是虚词：副词、介词、连词、助词、叹词和拟声词。这是传统语法学对汉语词汇的类别标准。计算语言学界中一些更复杂的分类标准也是以此作为基准的。

另一方面，在后面章节的语义角色标注中，词性对判断句子的语义角色也起着至关重要的作用。因此，无论是对于句法分析还是对于语义分析，对词性标注都是自然语言处理的一项重要的基础工作。

关于词性标注歧义的问题，英文中根据对Brown语料库进行统计，按歧义程度排列的词型数目DeRose（1988）给出了表5.1所示的Brown语料库词性标记歧义表。

表5.1 Brown语料库词性标记歧义表

| 无兼类只有1个标记  | 35 340 |
| ------------------ | ------ |
| 有兼类有2～7个标记 | 4 100  |
| 2个标记            | 3 764  |
| 3个标记            | 264    |
| 4个标记            | 61     |
| 5个标记            | 12     |
| 6个标记            | 2      |
| 7个标记            | 1      |

由表5.1可知，英语中的大多数单词都是没有歧义的，也就是这些单词只有一个单独的标记。但是，汉语与印欧语言不同，汉语缺乏丰富的形态变化，无法从词的形态变化来判别汉语词汇的词性。而且，汉语中常用词的兼类现象非常严重。根据对北京大学计算语言学研究所在网上公布的200万个汉字语料进行统计，其中兼类词占11%，这和英语差不多，但是这些兼类词的词频却占总词频的47%（张虎等人，2004）。因此，虽然兼类词占汉语词汇很小的一部分，但是由于兼类使用的程度高，兼类现象复杂，范围面广，因此，汉语的词性标注（POS Tagging）的主要任务与汉语分词差别不大，主要仍是消歧问题。

### 5.1.2 宾州树库的词性标注规范

虽然大家都承认12种词类的基准分类，但在计算语言学界，词类划分的很多细节却从未统一过。中科院ICTCLAS和前文的《北大规范》的词类总数都为39个。北大计算语言学研究所开发的语料库加工规范中，基本词类代码有26个，后来又增加了74个扩充代码，标记集中共计104个。而各个大型网站的词性标注都各有各的标准，最少的有17个，最多的有173个。单从数字上看，虽然标准复杂，但仔细观察后发现大同小异：有的是《北大规范》的精简版，有的则以《北大规范》为基础，增加了多个类别层次。

那么，我们使用哪种分类标准呢？从词性对句子结构的标识作用来看，本书使用的词性标注规范为宾州树库（Penn Treebank）中的《汉语词性标注规范》，以下简称《宾州规范》。表5.2所示为宾州树库的词性标注规范。

表5.2 宾州树库的词性标注规范

| 词性标记 | 英文名称                             | 中文名称                | 例子                                        |
| -------- | ------------------------------------ | ----------------------- | ------------------------------------------- |
| AD       | adverbs                              | 副词                    | “还”                                        |
| AS       | Aspect marker                        | 体标记                  | 了，着，过，“的（我是去年来的）”            |
| BA       | in ba-const                          | 把/将                   | 把，将                                      |
| CC       | Coordinating conjunction             | 并列连词                | “和”“与”“或”“或者”                          |
| CD       | Cardinal numbers                     | 数字/基数词             | “一百”                                      |
| CS       | Subordinating conj                   | 从属连词                | 若，如果，如                                |
| DEC      | for relative-clause etc              | 标句词，关系从句“的”    | 我买“的”书                                  |
| DEG      | Associative                          | 所有格/联结作用“的”     | 我“的”书                                    |
| DER      | in V-de construction, and V-de-R     | V得，表示结果补语的“得” | 跑“得”气喘吁吁                              |
| DEV      | before VP                            | 表示方式状语的“地”      | 高兴/VA地/DEV说/VV                          |
| DT       | Determiner                           | 限定词                  | 这                                          |
| ETC      | Tag for words in coordination phrase | “等”, “等等”            | 科技文教 等 /ETC领域“等”, “等等”            |
| FW       | Foreign words                        | 外语词                  | ISO                                         |
| IJ       | interjection                         | 感叹词                  | 啊                                          |
| JJ       | Noun-modifier other than nouns       | 其他名词修饰语          | 共同/JJ的/DEG目的/NN，她/PN是/VC女/JJ的/DEG |
| LB       | in long bei-construction             | 长“被”                  | “被”他打了                                  |
| LC       | Localizer                            | 方位词                  | 桌子“上”                                    |
| M        | Measure word (including classifiers) | 量词                    | 一“间”房子                                  |
| MSP      | Some particles                       | 其他结构助词            | 他/PN所/MSP需要/VV的/DEC。所，而，以，而    |
| NN       | Common nouns                         | 其他名词，普通名词      | 桌子                                        |
| NR       | Proper nouns                         | 专有名词                | 北京                                        |
| NT       | Temporal nouns                       | 时间名词                | 一月，汉朝                                  |
| OD       | Ordinal numbers                      | 序数词                  | “第一”                                      |
| ON       | Onomatopoeia                         | 拟声词                  | “哗啦啦”                                    |
| P        | Prepositions（excluding把and被）     | 介词                    | “在”                                        |
| PN       | pronouns                             | 代词                    | “你”, “我”, “他”                            |
| PU       | Punctuations                         | 标点                    | ，。                                        |
| SB       | in long bei-construction             | 短被                    | 他被/SB训了/AS一顿/M                        |
| SP       | Sentence-final particle              | 句末助词                | 他好吧[SP]了，呢，吧，啊，呀，吗            |
| VA       | Predicative adjective                | 谓语形容词              | 花很 红/VA红彤彤 雪白 丰富                  |
| VC       | Copula                               | 系动词                  | “是”“为”“非”                                |
| VE       | as the main verb                     | “有”作为主要动词        | “有”, “无”                                  |
| VV       | Other verbs                          | 其他动词，普通动词      | 走，可能，喜欢                              |

宾州规范的词性标注标记集有如下33种。动词和形容词（4）:VA、VC、VE、VV。名词（3）:NR、NT、NN、方位词（1）:LC。代词（1）:PN。限定词和数词（3）:DT、CD、OD。度量词（1）:M。副词（1）:AD。介词（1）:P。连词（2）:CC、CS。助词（8）:DEC、DEG、DER、DEV、SP、AS、ETC、MSP。其他（8）:IJ、ON、PU、JJ、FW、LB、SB、BA。

《宾州规范》在实词上与《北大规范》大同小异，但在虚词上差异较大。下面给出《宾州规范》词性标注的详细说明（读者可以以此与《北大规范》的虚词进行比较）。

1．虚词：DEC、DEG、DER、DEV、AS、SP、ETC、MSP

1）“的”作为补语标记/名词化标记：DEC（的，之）

例如，吃的DEC。

模式：S/VP DEC{NP}。

注：“的”还有其他标记。

❑ DEC：他 的/DEG车。

❑ SP：他 是/VC一定 要 来 的/SP。

❑ AS：他 是/VC在 这里 下 的/AS车。

2）“的”作为关联标记或所有格标记：DEG

模式：NP/PP/JJ/DT DEG{NP}。

3）补语短语 得：DER

在V-得-R和V-得结构中，“得”标记为DER。

注：有些以“得”结尾的搭配不是V-得结构，如记得、获得是动词。

4）方式“地”:DEV

当“地”出现在“XP地VP”中时，XP修饰VP。在一些古典文学中，“的”也用于这种情景，此时“的”也标注为DEV。

5）动态助词：AS

动态助词仅包括“着、了、过、的”。

6）句末助词：SP

SP经常出现在句末。例如，他好吧[SP]？

有时，句末助词用于表停顿。例如，他 吧[SP]，人 很 好。

例如，了、呢、吧、啊、呀、吗。

7）ETC

ETC用于标注“等”、“等等”。

8）其他助词：MSP

“所、以、来、而”，当它们出现在VP前时，标注为MSP。

所：他 所[MSP] 需要 的/DEC。

以或来：用……以/MSP（或来）维持。

而：为……而[MSP]奋斗。

2．“被”字结构

1）长“被”结构：LB

仅包括“被、叫、给、为（口语中）”，当它们出现在被字结构NP0+LB+NP1+VP中。

例如，他被/LB我训了/AS一顿/M。

注：当“叫”作为兼语动词时，“叫”标注为VV。

例如，他叫/VV你去。

2）短“被”结构：SB（仅包括口语中的“被、给”）

NP0+SB+VP，他 被/SB训了/AS一顿/M。

注：“给”有其他标记：LB、VV和P。

例如，你 给/P他 写 封/M信。

3．“把”字结构：BA

仅包括“把、将”，当它们出现在把字结构（NP0+BA+NP1+VP）中。

例如，他 把/BA你 骗 了/AS。

注：“将”有其他标记，AD和VV。例如，他 将/VV了/AS我 的/DEG军。

4．其他名词修饰语：JJ

包括如下三种类型。

（1）区别词。只修饰模式JJ+的+{N}或JJ+N中的名词，且一定要有“的”，它们不能被程度副词修饰。

例如，共同/JJ的/DEG目标/NN，她是[VC]女/JJ的/DEG。

（2）带有连字符的复合词。

通常为双音节词JJ+N。例如，留美/JJ学者/NN。

（3）形容词。新/JJ消息/NN。

模式：JJ+N。

注：当“的/DEC”在形容词和名词中间时，形容词标记为VA。

5．外来词：FW

FW仅用于：当词性标注标记在上下文中不是很清楚时。外来词不包括外来词的翻译，不包括混合中文的词（如卡拉OK/NN、A型/NN），不包括词义和词性在文中都是清楚的词。此外，《宾州规范》还给出了与《北大规范》的词性转换对照表（见表5.3）

表5.3 《宾州规范》与《北大规范》的词性转换对照表

| 中文词性名称   | 英文标签         | 宾州规范         | 北大规范 |
| -------------- | ---------------- | ---------------- | -------- |
| 总标签数       | total tags       | 33               | 26       |
| 名词           | nouns            | 3                | 3        |
| 时间名词       | temporal noun    | NT               | t        |
| 动名词         | verbal           | noun NN          | V[+nom]  |
| 专有名词       | proper noun      | NR               | n        |
| 其他名词       | other noun       | NN               | n、s     |
| 方位词         | localizer        | LC               | f        |
| 代词           | pronouns         | PN               | m        |
| 动词           | verbs            | 4                | 3        |
| 系动词         | shi4             | VC               | V        |
| “有”动词       | you3             | VE、VV           | v、a、z  |
| 其他动词       | other verbs      | W、VA            | V        |
| 副词           | Adverb           | AD               | d        |
| 介词           | prepositions     | P                | p        |
| 限定词及其相关 | DP-related       | 4                | 2        |
| 限定词         | determiner       | DT               | r        |
| 数词           | number           | CD、OD           | m        |
| 量词           | measure word     | M                | q        |
| 连词           | conjunctions     | 2                | 4        |
| 并列连词       | coord, conj      | CC               | c        |
| 从属连词       | subord. conj     | CS               | c        |
| 助词           | particles        | 8                | 2        |
| 体标记         | aspect marker    | AS               | u        |
| 助词           | 的               | DEC、DEG、AS、SP | u        |
| 助词           | 地               | DEV              | u        |
| 助词           | 得               | DER              | u        |
| 句末助词       | sent-final part. | SP               | y        |
| 助词           | 等               | ETC              | ??       |
| 其他助词       | other particles  | MSP              | u        |
| 其他词类       | others           | 8                | 4        |
| 叹词           | interjection     | IJ               | e        |
| 拟声词         | sound word       | ON               | o        |
| 标点符号       | punctuation      | PU               | w        |
| 名词修饰成分   | noun-modifier    | JJ               | b        |
| 外来词         | foreign words    | FW               | ??       |
| “被”字结构     | 被               | LB、SB           | p        |
| “把”字结构     | 把               | BA               | p        |

### 5.1.3 stanfordNLP标注词性

中文自动词性标注的算法很多，基本都属于概率图模型的范畴，这部分的算法思想前面已经讲过。本节所使用的是基于最大熵的词性标注算法。在诸多系统中，最著名的是stanfordNLP的词性标注模块。下面简要介绍stanfordNLP词性标注模块的自动标注和模型训练过程。

第1章简单介绍过一些开源的词性标注系统。其中，使用Python整合了Stanford Postagger模块进行词性标注。本节给出stanford-corenlp项目的Java构建方法。

（1）软件包下载：有关Stanford软件包的安装在第1章中讲过一部分，本节略。

（2）项目安装。

Stanford的所有项目均构建在Java的Eclipse IDE下。读者可以创建一个Java项目，并确定该项目名称，名称统一为stanfordNLP。工作空间和项目的字符集均使用UTF-8 （Windows/Linux）。使用的包为第1章讲过的stanford-corenlp，下载文件名为stanford-corenlp-full-2015-12-09.zip，汉语模型包为stanford-chinese-corenlp-2015-12-08-models.jar。下面给出所有的依赖包和语言模型包目录（见图5.1）。

![img](https://cdn.nlark.com/yuque/0/2021/jpeg/21473765/1631784654694-7eeef4cd-959b-4c0e-b2e2-c11ff27aff3e.jpeg)

图5.1 stanford-corenlp依赖包和语言模型包

图5.1中下图为部分源代码目录。使用此框架的一个重要原因是其运行的词性标注结果遵循宾州树库的词性标注规范。

我们编写了一个词性标注的测试例子程序，其他的测试例子版本参见http://new. galalaly.me//2011/05/tagging-text-with-stanford-pos-tagger-in-java-applications/。

​        package edu.stanford.testdemo;

​        import java.io.BufferedReader;

​        import java.io.StringReader;

​        import java.util.ArrayList;

​        import java.util.List;

​        import edu.stanford.nlp.ling.HasWord;

​        import edu.stanford.nlp.tagger.maxent.MaxentTagger;

​        public class PostagDemo {

​            public static void main(String[] args) {

​                //标注

​                String model = "models/pos-tagger/chinese-distsim/chinese-distsim.tagger";

​                String content = "你们 是 祖国 美丽 盛开 的 花朵";

​                MaxentTagger tagger = new MaxentTagger(model);

​                List<List<HasWord>> sentences = MaxentTagger.tokenizeText(new BufferedReader

​    (new StringReader(content)));

​                for (List<HasWord> sentence : sentences) {

​                    List<edu.stanford.nlp.ling.TaggedWord> tSentence = tagger.tagSentence

​    (sentence);

​                    System.out.println(tSentence);

​                }

​            }

​        }

输出结果如下。

​        Reading POS tagger model from models/pos-tagger/chinese-distsim/chinese-distsim.

​    tagger ... done [0.6 sec].

​        [你们/PN, 是/VC, 祖国/NN, 美丽/VA, 盛开/VV, 的/DEC, 花朵/NN]

在Stanford中文词性标注模型中，可以使用两个类词性标注模型，分别为chinese-distsim.tagger和chinese-nodistsim.tagger。

❑ chinese-distsim.tagger。

语料：基于来自中国内地和中国香港的CTB 7.0语料上训练得到，并做了相似性聚类。

标注集：中文LDCPOS树库标记集。

性能：对中文和中国香港文本的识别精度为93.99%（未知词为84.60%）。

❑ chinese-nodistsim.tagger。

语料：同样基于来自中国内地和中国香港的CTB 7.0语料上训练得到，但未做相似性聚类。

标注集：中文LDCPOS树库标记集。

性能：对中文和中国香港文本的识别精度为93.46%（未知词为79.40%）。

### 5.1.4 训练模型文件

在实际应用中，用户一般都根据自己的需求，自定义自己的模型。下面简要介绍模型的训练方法。

在模型文件的chinese-distsim目录下，有一个名为chinese-distsim.tagger的文件。它是stanford词性标注的模型文件，与它并列的还有一个训练时使用的配置文件chinese-distsim.tagger.props。我们对该文件做一些简单的修改即可完成训练过程。但对刚刚接触这个库的读者而言，很多参数可能都不太熟悉。为了使读者能够加深了解每个参数的意义，我们专门编写了一个程序，用于生成样本的props配置文件。该文件对于每个配置选项都提供了完整的注释，便于读者进一步学习。

首先，回顾一下第1章中使用过的两个python类：StanfordCoreNLP类和其子类StanfordPOSTagger类。StanfordPOSTagger类专门用于处理词性标注。下面在这个类中添加如下两个方法。

（1）buildprop方法：用来创建属性文件的命令行指令。

​            def __buildprop(self): #创建属性文件

​                self.propline = 'java -mx1g -cp "'+self.jarpath+'" '+self.classfier+'

​    -genprops'

（2）genpropfile方法：用来输出创建好的属性文件。

​            def genpropfile(self, propath): # 获取属性文件

​                self.__buildprop()

​                propfile = os.popen(self.propline, 'r').read()

​                self.savefile(propath, propfile)

​                print "save properties to ", propath

然后，输出创建的结果，内容如下。

​        \# -＊- coding: utf-8 -＊-

​        import sys

​        import os

​        from stanford import StanfordPOSTagger

​        reload(sys)  # 设置 UTF-8输出环境

​        sys.setdefaultencoding('utf-8')

​        \# print os.environ

​        root = 'X:/nltk_data/stanford-corenlp/'

​        modelpath = root+"models/pos-tagger/chinese-distsim/chinese-distsim.tagger"

​        st = StanfordPOSTagger(root, modelpath)

​        propspath = "my.tagger.props"

​        st.genpropfile(propspath)

输出结果：

在当前目录（你的python执行文件目录）下生成一个空的my.tagger.props。因为创建的文件比较大，所以只给出这个文件的部分代码，内容如下。

​        …

​        \# Model file name (created at train time; used at tag and test time)

​        \# (you can leave this blank and specify it on the commandline with -model)

​        \# model =

​        \# Path to file to be operated on (trained from, tested against, or tagged)

​        \# Specify -textFile <filename> to tag text in the given file, -trainFile <filename> to

​        \# to train a model using data in the given file, or -testFile <filename> to test

​    your

​        \# model using data in the given file.  Alternatively, you may specify

​        \# -dump <filename> to dump the parameters stored in a model or

​        \# -convertToSingleFile <filename> to save an old, multi-file model (specified as

​    -model)

​        \# to the new single file format.  The new model will be saved in the file filename.

​        \# If you choose to convert an old file, you must specify

​        \# the correct 'arch' parameter used to create the original model.

​        \# trainFile =

​        \# Path to outputFile to write tagged output to.

​        \# If empty, stdout is used.

​        \# outputFile =

​        …

受篇幅的限制，我们不可能给出样本配置文件中的各个选项的含义，读者可以根据这个样本的配置文件自行了解。这里仅给出如下几个必要参数的说明。

❑ model。训练完成后的需要保存的模型文件路径。

❑ trainFile。训练集文件名。

❑ tagSeparator。训练集中词汇与标签的分割符(“_”)。

❑ encoding。默认使用UTF-8字符集。

❑ arch。特征模板规则：words(-1,1), unicodeshapes(-1,1), order(2), suffix(4)。

words(-1,1)：前一词，当前词，后一词。

unicodeshapes(-1,1):unicode字符集，规则同上。

order(2)：从前两个标签来预测当前标签。

suffix(4)：试图从当前词的前4个字来预测未知词或稀有词的词性。

❑ search。默认优化算法为owlqn，但该算法未发布出来，可选的算法有owlqn2或qn。

❑ iterations。算法迭代次数，默认为100。

下面尝试使用该词性标注模块构建一个自己的mini模型。

一个mini的训练集文件如下。

​      在_P 包含_VV 问题_NN 的_DEC 所有_DT 解_VV 的_DEC 解空间_NN 树_NN 中_LC , _PU 按照_P 深

  度优先_NN 搜索_NN 的_DEC 策略_NN , _PU 从_P 根节点_NN 出发_VV 深度_JJ 探索_NN 解空间_NN 树

  _NN 。_PU

手工编辑my.tagger.props文件，产生完整配置文件信息，内容如下。

​                      model = my.model.tagger

​                       arch  =  generic, suffix(4), prefix(4), unicodeshapes(-1,1),

  unicodeshapeconjunction(-1,1), words(-2, -2), words(2,2)

​                wordFunction = edu.stanford.nlp.util.UTF8EquivalenceFunction

​                  trainFile = train.txt

​              closedClassTags =

​      closedClassTagThreshold = 40

​      curWordMinFeatureThresh = 1

​                      debug = false

​                debugPrefix =

​                tagSeparator = _

​                  encoding = utf-8

​                iterations = 100

​                       lang = chinese

​        learnClosedClassTags = false

​              minFeatureThresh = 3

​                openClassTags =

​      rareWordMinFeatureThresh = 3

​                rareWordThresh = 20

​                      search = owlqn2

​                        sgml = false

​                sigmaSquared = 0.0

​                       regL1 = 0.75

​                    tagInside =

​                    tokenize = false

​              tokenizerFactory =

​              tokenizerOptions =

​                     verbose = false

​                verboseResults = true

​          veryCommonWordThresh = 250

​                    xmlInput = null

​                    outputFile =

​                outputFormat = slashTags

​          outputFormatOptions =

​                    nthreads = 1

继续修改StanfordPOSTagger类。在此类中加入生成训练文件的如下两个方法。

（3）buildmodel方法：用来创建模型文件的命令行指令。

​            def __buildtrain(self, propspath): # 创建模型文件

​                self.trainline = 'java -mx4g -cp "'+self.jarpath+'" '+self.classfier +'

​    -props "'+propspath+'"'

（4）trainmodel方法：用来输出创建好的模型文件。

​            def trainmodel(self, propspath): # 训练模型

​                self.__buildtrain(propspath)

​                os.system(self.trainline)

​                print "save model to model.tagger"

然后，输出创建的结果，内容如下。

​      \# -＊- coding: utf-8 -＊-

​      import sys

​      import os

​      from stanford import StanfordPOSTagger

​      reload(sys)  # 设置 UTF-8输出环境

​      sys.setdefaultencoding('utf-8')

​      \# print os.environ

​      root = 'E:/nltk_data/stanford-corenlp/'

​      modelpath = root+"models/pos-tagger/chinese-distsim/chinese-distsim.tagger"

​        st = StanfordPOSTagger(root, modelpath)

​        propspath = "my.tagger.props"

​        st.trainmodel(propspath)

输出结果：

在当前目录（你的python执行文件目录）下生成了一个my.model.tagger的二进制文件。因为是为了演示训练过程，该文件只有4KB。

最后，给出训练过程的部分输出日志，内容如下。

​        ……

​        TaggerExperiments: adding word/tags

​        Loading tagged words from train.txt

​        Read 25 words from train.txt [done].

​        Read 1 sentences, min 25 words, max 25 words.

​        Featurizing tagged data tokens...

​        Featurized 26 data tokens [done].

​        xSize [num Phi templates] = 25; ySize [num classes] = 9

​        Hashing histories ...

​        Hashed 25 histories.

​        Hashing populated histories ...

​        Hashed populated histories.

​        TaggerExperiments.getFeaturesNew: initializing fnumArr.

​          length of sTemplates keys: 175

​        getFeaturesNew adding features ...

​          total feats: 175, populated: 104

​          Max features per x, y pair: 9

​          Max non-zero y values for an x: 9

​          Number of non-zero feature x, y pairs: 192

​          Number of zero feature x, y pairs: 33

​        end getFeaturesNew.

​        Samples from train.txt

​        Number of features: 104

​        Tag set: [P, VV, NN, DT, JJ, DEC, PU, .$$., LC]

​         pcond initialized

​         zlambda initialized

​         ftildeArr initialized

​        QNMinimizer called on double function of 104 variables, using M = 10.

​      Iter. 0: neg. log cond. likelihood = 57.12783901074175 [1 calls to valueAt]

  An explanation of the output:

​      Iter          The number of iterations

​      evals         The number of function evaluations

​      SCALING       <D> Diagonal scaling was used; <I> Scaled Identity

​      LINESEARCH    [## M steplength]  Minpack linesearch

​                      1-Function value was too high

​                      2-Value ok, gradient positive, positive curvature

​                      3-Value ok, gradient negative, positive curvature

​                      4-Value ok, gradient negative, negative curvature

​                    [.. B]  Backtracking

​      VALUE         The current function value

​      TIME          Total elapsed time

​      |GNORM|       The current norm of the gradient

​      {RELNORM}     The ratio of the current to initial gradient norms

​      AVEIMPROVE    The average improvement / current value

​      EVALSCORE     The last available eval score

​      Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE

  EVALSCORE

​      Iter 1 evals 1 <D> [B 1.000E-1] 5.093E1 0.00s

​      Iter. 1: neg. log cond. likelihood = 48.191508920927475 [2 calls to valueAt]

  |5.490E0| {4.211E-1} 0.000E0 -

​      Iter 2 evals 2 <D> [B 1.000E-1] 4.949E1 0.00s

​      Iter. 2: neg. log cond. likelihood = 45.91531010406181 [3 calls to valueAt]

  |4.733E0| {3.630E-1} 1.456E-2 -

​      ……

​      Iter 21 evals 21 <D> [B 1.000E0] 4.229E1 0.02s

​      Iter. 21: neg. log cond. likelihood = 26.931394983455895 [30 calls to valueAt]

​      QNMinimizer terminated due to average improvement: | newest_val - previous_val

  | / |newestVal| < TOL

​      Total time spent in optimization: 0.02s

​      After optimization neg (penalized) log cond likelihood: 26.93

​      Non-zero parameters: 25/104 (24.04%)

​      Checking model correctness; x size 25 , ysize 9

​      Constraint 0 not satisfied emp 0.0769 exp 0.0535 diff 0.0234 lambda 0

​      Constraint 1 not satisfied emp 0.0769 exp 0.0825 diff 0.0056 lambda 0

​       ……

​      Constraint 102 not satisfied emp 0.0769 exp 0.0475 diff 0.0294 lambda 0.3403

​      Model is not correct

​      Saving dictionary of 8 words ...

​        Extractors list:

​        Extractors[Extractor(-1, word),      Extractor(0, word),      Extractor(1, word),

​    ExtractorFrames$ExtractorContinuousTagConjunction(-2, tag), Extractor(-1, tag), edu.

​    stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorTwoWords(w0, w-1), edu.stanford.

​    nlp.tagger.maxent.ExtractorFrames$ExtractorWordTag(w0, t-1),    Extractor(-2, word),

​    Extractor(2, word)]

​        rareExtractors[ExtractorWordSuff(len1, w0),         ExtractorWordSuff(len2, w0),

​    ExtractorWordSuff(len3, w0), ExtractorWordSuff(len4, w0), ExtractorWordPref(len1, w0),

​    ExtractorWordPref(len2, w0), ExtractorWordPref(len3, w0), ExtractorWordPref(len4, w0),

​    ExtractorWordShapeClassifier(-1, chris4),   ExtractorWordShapeClassifier(0, chris4),

​    ExtractorWordShapeClassifier(1, chris4),

​    ExtractorWordShapeConjunction(-1,1, chris4)]

​        Training POS tagger done [0.2 sec].

​        save model to mymodel.tagger
